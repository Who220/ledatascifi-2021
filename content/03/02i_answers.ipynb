{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers to Pandas Exercises\n",
    "\n",
    "There are many ways to solve each of these!\n",
    "\n",
    "Run each cell below in little incremental bits to really see how the code blocks work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader as pdr # IF NECESSARY, from terminal: pip install pandas_datareader \n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "start = datetime.datetime(2017, 1, 1) # you can specify start and end dates this way\n",
    "end = datetime.datetime(2021, 1, 27)\n",
    "macro_df = pdr.data.DataReader(['GDP','CPIAUCSL','UNRATE'], 'fred', start, end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "During class, I used this dataframe to go over [Pandas vocab](02b_pandasVocab), and we show how to\n",
    "- access 1 variable (note: `pd` calls this a \"series\" object, which is a 1D object instead of a 2D object)\n",
    "- access multiple vars\n",
    "- access, print, and change column names\n",
    "- access, print, reset, and set the index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- Q0: Do each of the four new golden rules for initial data exploration, from the lecture.\n",
    "- Q1: What is the second series above?\n",
    "- Q2: What is the frequency of the series?\n",
    "- Q3: What is the average ANNUAL GDP, based on the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  GDP  CPIAUCSL  UNRATE\n",
      "DATE                                   \n",
      "2017-01-01  19237.435   243.620     4.7\n",
      "2017-02-01        NaN   243.872     4.6\n",
      "2017-03-01        NaN   243.766     4.4\n",
      "2017-04-01  19379.232   244.274     4.5\n",
      "2017-05-01        NaN   244.069     4.4 \n",
      "---\n",
      "                  GDP  CPIAUCSL  UNRATE\n",
      "DATE                                   \n",
      "2020-09-01        NaN   260.149     7.8\n",
      "2020-10-01  21479.529   260.462     6.9\n",
      "2020-11-01        NaN   260.927     6.7\n",
      "2020-12-01        NaN   261.560     6.7\n",
      "2021-01-01        NaN   262.231     6.3 \n",
      "---\n",
      "Index(['GDP', 'CPIAUCSL', 'UNRATE'], dtype='object') \n",
      "---\n",
      "The shape is:  (49, 3) \n",
      "---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 49 entries, 2017-01-01 to 2021-01-01\n",
      "Freq: MS\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   GDP       16 non-null     float64\n",
      " 1   CPIAUCSL  49 non-null     float64\n",
      " 2   UNRATE    49 non-null     float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 1.5 KB\n",
      "Info: None \n",
      "---\n",
      "                GDP    CPIAUCSL     UNRATE\n",
      "count     16.000000   49.000000  49.000000\n",
      "mean   20630.206313  252.878469   5.034694\n",
      "std      862.963655    5.557894   2.524179\n",
      "min    19237.435000  243.620000   3.500000\n",
      "25%    19857.794250  248.721000   3.800000\n",
      "50%    20826.288000  252.899000   4.000000\n",
      "75%    21367.290000  257.387000   4.500000\n",
      "max    21747.394000  262.231000  14.800000 \n",
      "---\n",
      "UNRATE has 22 values and its top 10 most common are:\n",
      "3.8    7\n",
      "4.0    5\n",
      "3.6    5\n",
      "4.4    4\n",
      "3.7    4\n",
      "3.5    3\n",
      "4.1    3\n",
      "4.2    2\n",
      "4.3    2\n",
      "6.7    2\n",
      "Name: UNRATE, dtype: int64 \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# do your work here\n",
    "def insufficient_but_starting_eda(df,cat_vars_list=None):\n",
    "    '''\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DATAFRAME\n",
    "    cat_vars_list : LIST, optional\n",
    "        A list of strings containing variable names in the dataframe\n",
    "        for variables where you want to see the number of unique values\n",
    "        and the 10 most common values. Likely used for categorical values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None. It simply prints.\n",
    "    \n",
    "    Description\n",
    "    -------    \n",
    "    This function will print a MINIMUM amount of info about a new dataframe. \n",
    "    \n",
    "    You should ****look**** at all this output below and consider the data\n",
    "    exploration and cleaning questions from \n",
    "    https://ledatascifi.github.io/ledatascifi-2021/content/03/02e_eda_golden.html#member\n",
    "    \n",
    "    Also LOOK at more of the data manually. \n",
    "    \n",
    "    Then write up anything notable you observe.\n",
    "    \n",
    "    TIP: put this function in your codebook to reuse easily.\n",
    "    \n",
    "    PROTIP: Improve this function (better outputs, better formatting).\n",
    "    \n",
    "    FEATURE REQUEST: optionally print the nunique and top 10 values under the describe matrix\n",
    "    \n",
    "    FEATURE REQUEST: optionally print more stats (percentiles)\n",
    "    \n",
    "    '''\n",
    "    print(df.head(),  '\\n---')\n",
    "    print(df.tail(),  '\\n---')\n",
    "    print(df.columns, '\\n---')\n",
    "    print(\"The shape is: \",df.shape, '\\n---')\n",
    "    print(\"Info:\",df.info(), '\\n---') # memory usage, name, dtype, and # of non-null obs (--> # of missing obs) per variable\n",
    "    print(df.describe(), '\\n---') # summary stats, and you can customize the list!\n",
    "    if cat_vars_list != None:\n",
    "        for var in cat_vars_list:\n",
    "            print(var,\"has\",df[var].nunique(),\"values and its top 10 most common are:\")\n",
    "            print(df[var].value_counts().head(10), '\\n---')\n",
    "        \n",
    "insufficient_but_starting_eda(macro_df,['UNRATE'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some answers\n",
    "- Q0: What have we learned about the data? Anything to keep track of? (GDP is annual, others are quarterly)\n",
    "- Q1: Inflation (CPI)\n",
    "- Q2: Quarterly, but GDP is only annual\n",
    "- Q3: 20,630 (trillion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "- Q4: Download the annual *real* gdp from 1960 to 2018 from FRED and compute the average annual percent change\n",
    "- Q5: Compute the average gdp percent change within *each decade*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030766069353016783"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do your work here\n",
    "\n",
    "# v1:\n",
    "part2_df = pdr.data.DataReader(['GDPCA'], 'fred', 1960, 2018) \n",
    "part2_df['real_gdp_pct'] = part2_df['GDPCA'].pct_change()\n",
    "part2_df['real_gdp_pct'].mean()\n",
    "\n",
    "# prof notes: after students present, go through, bit by bit\n",
    "# then add comments (a la psuedo), \n",
    "# reiter access var: df[var], how methods apply to obj df[var].func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030766069353016783"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v1.1: chain the last 2 lines together\n",
    "part2_df = pdr.data.DataReader(['GDPCA'], 'fred', 1960, 2018) \n",
    "part2_df['GDPCA'].pct_change().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GDPCA    0.030766\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v1.2 that last line could be:    \n",
    "(part2_df\n",
    "     .pct_change()\n",
    "     .mean()\n",
    "     \n",
    ")\n",
    "\n",
    "# explain reasons for chaining: readable, no temp objects\n",
    "\n",
    "# breaking this up into 3 lines is silly but shows chaining over multiple lines\n",
    "# how can we add the first line (the DL) into this? (next block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030766069353016783"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v2.0: chaining - but involves a lambda function work around\n",
    "# don't cover until we go over lambdas\n",
    "(\n",
    "    # DL data\n",
    "    pdr.data.DataReader(['GDPCA','GDPA'], 'fred', 1960, 2018) \n",
    "    \n",
    "    # create the var\n",
    "    # syntax is: .assign(newname = fcn(df(var)))\n",
    "    # try this:\n",
    "    #.assign(sillyvar=1)\n",
    "    # but this df doesn't have a name! how do we access it?\n",
    "    # trick: \"lambda\" function. \n",
    "    #        here x is the object that assign is working on,\n",
    "    #        meaning what ever is produced right before .assign\n",
    "    #        which is just the **df** we DLed on the line above\n",
    "    #\n",
    "    # this is VERY COMMON in pandas chaining:\n",
    "    # .assign(newvarname = lambda <tempnameforpriorobj>:  <do stuff to tempnameforpriorobj>   )       \n",
    "    .assign(real_gdp_pct = lambda x: x['GDPCA'].pct_change())\n",
    "    \n",
    "    # grab the var and take its mean\n",
    "    ['real_gdp_pct'].mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030766069353016783"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v2.1: chaining - clean\n",
    "(\n",
    "    # DL data\n",
    "    pdr.data.DataReader(['GDPCA','GDPA'], 'fred', 1960, 2018) \n",
    "    # create var\n",
    "    .assign(real_gdp_pct = lambda x: x['GDPCA'].pct_change())\n",
    "    # get mean value\n",
    "    ['real_gdp_pct'].mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decade\n",
       "1960.0    0.047426\n",
       "1970.0    0.032352\n",
       "1980.0    0.031240\n",
       "1990.0    0.032220\n",
       "2000.0    0.019099\n",
       "2010.0    0.023165\n",
       "Name: real_gdp_pct, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5:\n",
    "import numpy as np\n",
    "# v2.1: chaining - clean\n",
    "(\n",
    "    # DL data\n",
    "    pdr.data.DataReader(['GDPCA','GDPA'], 'fred', 1960, 2018) \n",
    "    # create var pct change\n",
    "    .assign(real_gdp_pct = lambda x: x['GDPCA'].pct_change())\n",
    "    # get the decade from the index (do this BIT BY BIT)\n",
    "    .reset_index() # turn it into variable\n",
    "        # how to pull year out of date?\n",
    "        # DATE is a datetime series. dt is a way to access properities of the date \n",
    "    .assign(decade = lambda x: np.floor(x.DATE.dt.year/10)*10)\n",
    "    # for each decade = groupby!\n",
    "    .groupby('decade')\n",
    "    # take mean\n",
    "    ['real_gdp_pct'].mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "\n",
    "First, I'll load January data on unemployment, the Case-Shiller housing index, and median household income in three states (CA/MI/PA). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " DATA BEFORE FORMATTING: \n",
      "\n",
      "\n",
      "      CAUR  MIUR  PAUR      LXXRSA      DEXRSA      WDXRSA  MEHOINUSCAA672N  \\\n",
      "DATE                                                                          \n",
      "1990   5.2   7.8   5.1  100.471193         NaN   93.362855          63333.0   \n",
      "1991   7.1   8.8   6.6   95.569015   58.420806   89.706871          61797.0   \n",
      "1992   8.5   9.4   7.5   92.786926   59.748947   88.573807          62517.0   \n",
      "1993   9.7   7.6   7.3   85.246295   61.564205   89.065118          59529.0   \n",
      "1994   9.2   7.1   6.6   77.395052   64.526663   88.988467          60464.0   \n",
      "1995   7.7   5.2   5.8   76.376389   68.973289   89.670303          61846.0   \n",
      "1996   7.7   4.9   5.9   73.919989   73.582339   88.655369          63176.0   \n",
      "1997   6.8   4.7   5.3   74.536884   79.347642   88.775224          63245.0   \n",
      "1998   6.0   4.0   4.7   81.035037   85.183613   90.108149          64349.0   \n",
      "1999   5.6   3.9   4.5   92.140086   92.433567   94.188054          67156.0   \n",
      "2000   5.0   3.3   4.1  101.031209  100.145625  100.871832          69696.0   \n",
      "2001   4.8   4.4   4.3  112.031476  107.327208  113.794411          68413.0   \n",
      "2002   6.5   6.4   5.5  122.706507  111.468549  127.245701          67600.0   \n",
      "2003   6.8   6.6   5.8  145.752401  115.704198  146.676851          68695.0   \n",
      "2004   6.5   6.8   5.5  178.773752  119.772720  169.535303          66782.0   \n",
      "2005   5.8   7.2   5.2  221.471364  123.264823  210.799937          67918.0   \n",
      "2006   5.0   6.8   4.7  268.208844  126.872678  250.272528          70316.0   \n",
      "2007   4.9   6.9   4.3  270.804920  118.163891  241.411126          68890.0   \n",
      "2008   6.0   7.1   4.7  226.111966  100.378575  215.656581          67865.0   \n",
      "2009   9.7  10.9   7.0  167.831216   77.690858  174.183926          67051.0   \n",
      "\n",
      "      MEHOINUSMIA672N  MEHOINUSPAA672N  \n",
      "DATE                                    \n",
      "1990          56954.0          55181.0  \n",
      "1991          58957.0          55744.0  \n",
      "1992          57795.0          53523.0  \n",
      "1993          57064.0          54151.0  \n",
      "1994          60384.0          54877.0  \n",
      "1995          60872.0          57693.0  \n",
      "1996          63849.0          56807.0  \n",
      "1997          61728.0          59776.0  \n",
      "1998          65744.0          61333.0  \n",
      "1999          70942.0          58119.0  \n",
      "2000          67755.0          62789.0  \n",
      "2001          65206.0          62966.0  \n",
      "2002          60871.0          60562.0  \n",
      "2003          62734.0          59823.0  \n",
      "2004          57331.0          59841.0  \n",
      "2005          60278.0          60760.0  \n",
      "2006          61835.0          61619.0  \n",
      "2007          61024.0          59870.0  \n",
      "2008          59264.0          61185.0  \n",
      "2009          54939.0          57540.0  \n",
      "\n",
      "\n",
      " DATA AFTER FORMATTING: \n",
      "\n",
      "\n",
      "     Unemployment               HouseIdx                         MedIncome  \\\n",
      "               CA    MI   PA          CA          MI          PA        CA   \n",
      "DATE                                                                         \n",
      "1990          5.2   7.8  5.1  100.471193         NaN   93.362855   63333.0   \n",
      "1991          7.1   8.8  6.6   95.569015   58.420806   89.706871   61797.0   \n",
      "1992          8.5   9.4  7.5   92.786926   59.748947   88.573807   62517.0   \n",
      "1993          9.7   7.6  7.3   85.246295   61.564205   89.065118   59529.0   \n",
      "1994          9.2   7.1  6.6   77.395052   64.526663   88.988467   60464.0   \n",
      "1995          7.7   5.2  5.8   76.376389   68.973289   89.670303   61846.0   \n",
      "1996          7.7   4.9  5.9   73.919989   73.582339   88.655369   63176.0   \n",
      "1997          6.8   4.7  5.3   74.536884   79.347642   88.775224   63245.0   \n",
      "1998          6.0   4.0  4.7   81.035037   85.183613   90.108149   64349.0   \n",
      "1999          5.6   3.9  4.5   92.140086   92.433567   94.188054   67156.0   \n",
      "2000          5.0   3.3  4.1  101.031209  100.145625  100.871832   69696.0   \n",
      "2001          4.8   4.4  4.3  112.031476  107.327208  113.794411   68413.0   \n",
      "2002          6.5   6.4  5.5  122.706507  111.468549  127.245701   67600.0   \n",
      "2003          6.8   6.6  5.8  145.752401  115.704198  146.676851   68695.0   \n",
      "2004          6.5   6.8  5.5  178.773752  119.772720  169.535303   66782.0   \n",
      "2005          5.8   7.2  5.2  221.471364  123.264823  210.799937   67918.0   \n",
      "2006          5.0   6.8  4.7  268.208844  126.872678  250.272528   70316.0   \n",
      "2007          4.9   6.9  4.3  270.804920  118.163891  241.411126   68890.0   \n",
      "2008          6.0   7.1  4.7  226.111966  100.378575  215.656581   67865.0   \n",
      "2009          9.7  10.9  7.0  167.831216   77.690858  174.183926   67051.0   \n",
      "\n",
      "                        \n",
      "           MI       PA  \n",
      "DATE                    \n",
      "1990  56954.0  55181.0  \n",
      "1991  58957.0  55744.0  \n",
      "1992  57795.0  53523.0  \n",
      "1993  57064.0  54151.0  \n",
      "1994  60384.0  54877.0  \n",
      "1995  60872.0  57693.0  \n",
      "1996  63849.0  56807.0  \n",
      "1997  61728.0  59776.0  \n",
      "1998  65744.0  61333.0  \n",
      "1999  70942.0  58119.0  \n",
      "2000  67755.0  62789.0  \n",
      "2001  65206.0  62966.0  \n",
      "2002  60871.0  60562.0  \n",
      "2003  62734.0  59823.0  \n",
      "2004  57331.0  59841.0  \n",
      "2005  60278.0  60760.0  \n",
      "2006  61835.0  61619.0  \n",
      "2007  61024.0  59870.0  \n",
      "2008  59264.0  61185.0  \n",
      "2009  54939.0  57540.0  \n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA AND CONVERT TO ANNUAL\n",
    "\n",
    "start = 1990 # pandas datareader can infer these are years\n",
    "end = 2018\n",
    "macro_data = pdr.data.DataReader(['CAUR','MIUR','PAUR', # unemployment \n",
    "                                  'LXXRSA','DEXRSA','WDXRSA', # case shiller index in LA, Detroit, DC (no PA  available!)\n",
    "                                  'MEHOINUSCAA672N','MEHOINUSMIA672N','MEHOINUSPAA672N'], #  \n",
    "                                 'fred', start, end)\n",
    "macro_data = macro_data.resample('Y').first() # get's the first observation for each variable in a given year\n",
    "\n",
    "# CLEAN UP THE FORMATING SOMEWHAT\n",
    "\n",
    "macro_data.index = macro_data.index.year\n",
    "print(\"\\n\\n DATA BEFORE FORMATTING: \\n\\n\")\n",
    "print(macro_data[:20]) # see how the data looks now? ugly variable names, but its an annual dataset at least\n",
    "macro_data.columns=pd.MultiIndex.from_tuples([\n",
    "    ('Unemployment','CA'),('Unemployment','MI'),('Unemployment','PA'),\n",
    "    ('HouseIdx','CA'),('HouseIdx','MI'),('HouseIdx','PA'),\n",
    "    ('MedIncome','CA'),('MedIncome','MI'),('MedIncome','PA')\n",
    "    ])\n",
    "print(\"\\n\\n DATA AFTER FORMATTING: \\n\\n\")\n",
    "print(macro_data[:20]) # this is a dataset that is \"wide\", and now \n",
    "                       # the column variable names have 2 levels - var name, \n",
    "                       # and unit/state that variable applies to\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q6: for each decade and state, report the average annual CHANGE (level, not percent) in unemployment\n",
    "- Q7: for each decade and state, report the average annual PERCENT CHANGE in house prices and household income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do your work here: \n",
    "\n",
    "# let's pseudocode\n",
    "\n",
    "# q6 \n",
    "# get decade variable\n",
    "# get annual change/difference (level) in unemploy for each state\n",
    "# average unemploy for each state within decade\n",
    "\n",
    "# q7\n",
    "# get decade variable\n",
    "# get annual pct change in house price and income for each state\n",
    "# average those for each state within decade\n",
    "\n",
    "# HEY! those are similar - let's combine:\n",
    "\n",
    "# get decade variable\n",
    "# get annual change in unemploy for each state\n",
    "# get annual pct change in house price and income for each state\n",
    "# average unemploy for each state within decade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error easter-egg hunt\n",
    "\n",
    "This code is _allllllllmost_ correct. It actually generates incorrect answers. If you figure out the problem and/or the solution, please submit an error fix via the \"edit\" button at the top of this page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">HouseIdx_pctch</th>\n",
       "      <th colspan=\"3\" halign=\"left\">MedIncome_pctch</th>\n",
       "      <th colspan=\"3\" halign=\"left\">unemploy_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th>CA</th>\n",
       "      <th>MI</th>\n",
       "      <th>PA</th>\n",
       "      <th>CA</th>\n",
       "      <th>MI</th>\n",
       "      <th>PA</th>\n",
       "      <th>CA</th>\n",
       "      <th>MI</th>\n",
       "      <th>PA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decade</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>-0.71</td>\n",
       "      <td>-3.13</td>\n",
       "      <td>-2.07</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>4.44</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>7.52</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>7.22</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-2.42</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>41.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>5.84</td>\n",
       "      <td>5.16</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.54</td>\n",
       "      <td>-58.89</td>\n",
       "      <td>-71.11</td>\n",
       "      <td>-26.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HouseIdx_pctch             MedIncome_pctch             unemploy_diff  \\\n",
       "state              CA    MI    PA              CA    MI    PA            CA   \n",
       "decade                                                                        \n",
       "1990            -0.71 -3.13 -2.07            0.69  0.22 -0.46          4.44   \n",
       "2000             7.52 -1.20  7.22            0.01 -2.42 -0.03         41.00   \n",
       "2010             5.84  5.16  2.83            0.84  1.42  1.54        -58.89   \n",
       "\n",
       "                      \n",
       "state      MI     PA  \n",
       "decade                \n",
       "1990    -5.00   0.00  \n",
       "2000    70.00  25.00  \n",
       "2010   -71.11 -26.67  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', '{:,.2f}'.format)\n",
    "\n",
    "(\n",
    "    # reformat the data to tall:\n",
    "    macro_data.stack().swaplevel().sort_index().reset_index().rename(columns={'level_0':'state'})\n",
    "    \n",
    "    # create vars <---- this is not even needed to explain this block!\n",
    "    .assign(\n",
    "            decade          = lambda x: 10*np.floor(x['DATE']/10).astype(int),\n",
    "            unemploy_diff   = lambda x: x['Unemployment'].diff(),\n",
    "            HouseIdx_pctch  = lambda x: x['HouseIdx'].pct_change(),\n",
    "            MedIncome_pctch = lambda x: x['MedIncome'].pct_change()    \n",
    "    )\n",
    "    \n",
    "    # opt A for output:\n",
    "    .pivot_table(index='decade',\n",
    "                 columns='state',\n",
    "                 values=['unemploy_diff','HouseIdx_pctch','MedIncome_pctch'])\n",
    "    .multiply(100) # for more meaningful displays \n",
    "    \n",
    "    # opt B for output + formatting (here, as percentages)\n",
    "#     .groupby(['state','decade'])\n",
    "#     [['unemploy_diff','HouseIdx_pctch','MedIncome_pctch']].mean()\n",
    "#     .multiply(100)\n",
    "#     # note about this: unemp isn't a % diff, but a p.p \n",
    "#     # so I make it explicit \n",
    "#     .style.format({'HouseIdx_pctch': '{0:,.2f}%',\n",
    "#                    'MedIncome_pctch': '{0:,.2f}%',\n",
    "#                    'unemploy_diff': '{0:,.2f} p.p.'}) \n",
    "    \n",
    ")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
